{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/Data/Customers.csv\")\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option('overwriteSchema','true').save(\"Tables/customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM <enter_name_here>.items LIMIT 1000\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/Data/Items_noheader.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "itemsSchema = StructType([\n",
    "    StructField(\"ItemId\", IntegerType(), True),\n",
    "    StructField(\"CurrentPrice\", StringType(), True),\n",
    "    StructField(\"Brand\", DoubleType(), True),\n",
    "    StructField(\"Class\", StringType(), True),\n",
    "    StructField(\"Category\", IntegerType(), True),\n",
    "    StructField(\"Color\", StringType(), True),\n",
    "    StructField(\"ProductName\", StringType(), True),\n",
    "    StructField(\"WholesaleCost\", DoubleType(), True)\n",
    "    ])\n",
    "df = spark.read.format(\"csv\").schema(itemsSchema).load(\"Files/Data/Items_noheader.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/Data/Customers.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = df['Customer_Name', 'State']\n",
    "print(customers.count())\n",
    "print(customers.distinct().count())\n",
    "display(customers.distinct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = df['Customer_Name', 'State'].where(df['State'] == 'California')\n",
    "print(customers.count())\n",
    "print(customers.distinct().count())\n",
    "display(customers.distinct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACustomers = df.select('Customer_Name', 'State').groupBy('State').count()\n",
    "display(CACustomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "yearofbirth = df.select(year('Birth_Date').alias('YearOfBirth')).groupBy('YearOfBirth').count().orderBy('YearOfBirth')\n",
    "display(yearofbirth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearofbirth.write.mode(\"overwrite\").parquet('Files/transformed_data/yearofbirth')\n",
    "print('Transformed Data Saved')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
